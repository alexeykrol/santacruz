Понял. Вот полностью очищенный текст статьи в формате Markdown. Я убрал все служебные пометки (вроде ``), оставив только оригинальные авторские сноски `[1]`, `[2]` и т.д., которые ведут к списку литературы.

***

# ВЫ ЖИВЕТЕ В КОМПЬЮТЕРНОЙ СИМУЛЯЦИИ?

**Ник Бостром**
*Факультет философии, Оксфордский университет*

## Аннотация
В этой статье утверждается, что по крайней мере одно из следующих утверждений истинно:
1.  Человеческий вид, скорее всего, вымрет, не достигнув «постчеловеческой» стадии.
2.  Любая постчеловеческая цивилизация крайне маловероятно будет запускать значительное число симуляций своей эволюционной истории (или ее вариаций).
3.  Мы почти наверняка живем в компьютерной симуляции.

Из этого следует, что вера в то, что мы однажды станем постлюдьми, которые запускают симуляции предков, ложна, если только мы уже не живем в симуляции. Также обсуждается ряд других последствий этого результата.

---

## I. ВВЕДЕНИЕ
Многие научно-фантастические произведения, а также прогнозы серьезных технологов и футурологов предсказывают, что в будущем будут доступны огромные объемы вычислительной мощности. Предположим на мгновение, что эти прогнозы верны. Одним из применением этих суперкомпьютеров будущими поколениями может стать запуск детальных симуляций их предков или людей, подобных им.

Поскольку их компьютеры будут невероятно мощными, они смогут запускать огромное количество таких симуляций. Предположим, что эти симулированные люди обладают сознанием (что верно, если симуляции достаточно детализированы и определенная, довольно широко принятая позиция в философии сознания верна). Тогда может оказаться, что подавляющее большинство умов, подобных нашему, принадлежат не оригинальной расе, а симулированным людям, созданным продвинутыми потомками оригинальной расы.

В таком случае можно утверждать, что рационально думать, что мы, скорее всего, находимся среди симулированных умов, а не среди оригинальных биологических. Следовательно, если мы не думаем, что мы в настоящее время живем в компьютерной симуляции, мы не имеем права верить, что у нас будут потомки, которые запустят множество таких симуляций своих предков. Такова основная идея. Остальная часть этой статьи изложит её более тщательно.

Помимо интереса, который этот тезис может представлять для тех, кто занимается футуристическими спекуляциями, есть и чисто теоретические выгоды. Аргумент дает стимул для формулирования некоторых методологических и метафизических вопросов, и он предлагает натуралистические аналогии для определенных традиционных религиозных концепций.

Структура статьи следующая. Сначала мы формулируем допущение, которое нам нужно заимствовать из философии сознания. Во-вторых, мы рассматриваем эмпирические причины полагать, что запуск огромного количества симуляций человеческих разумов будет в пределах возможностей будущей цивилизации. Затем следует ядро аргумента, использующее простую теорию вероятностей, и раздел, обосновывающий слабый принцип безразличия. Наконец, мы обсуждаем некоторые интерпретации дизъюнкции, упомянутой в аннотации.

## II. ДОПУЩЕНИЕ О СУБСТРАТНОЙ НЕЗАВИСИМОСТИ
Распространенным допущением в философии сознания является «субстратная независимость» (*substrate-independence*). Идея заключается в том, что ментальные состояния могут возникать (супервентны) на любом из широкого класса физических субстратов. При условии, что система реализует правильные вычислительные структуры и процессы, она может быть связана с сознательным опытом.

Не является обязательным свойством сознания его реализация на углеродных биологических нейронных сетях внутри черепа: кремниевые процессоры в компьютере в принципе могут делать то же самое. Аргументы в пользу этого тезиса даны в литературе, и хотя он не является полностью бесспорным, мы примем его здесь как данность.

Аргумент, который мы представим, не зависит, однако, от какой-либо очень сильной версии функционализма. Например, нам не нужно предполагать, что тезис о субстратной независимости обязательно истинен (аналитически или метафизически) — достаточно того, что *фактически* компьютер, выполняющий подходящую программу, будет сознательным. Более того, нам не нужно предполагать, что для создания разума на компьютере достаточно запрограммировать его так, чтобы он вел себя как человек во всех ситуациях (проходил тест Тьюринга и т.д.). Нам нужно лишь более слабое предположение: для возникновения субъективного опыта достаточно, чтобы вычислительные процессы человеческого мозга были структурно воспроизведены с подходящей детализацией, например, на уровне отдельных синапсов. Эта ослабленная версия субстратной независимости принимается довольно широко.

Нейротрансмиттеры и другие химические вещества явно играют роль в человеческом познании. Тезис о субстратной независимости не отрицает этого, а утверждает, что они влияют на субъективный опыт только через их влияние на вычислительную активность. Например, если не может быть разницы в субъективном опыте без разницы в синаптических разрядах, то необходимая детализация симуляции находится на синаптическом уровне (или выше).

## III. ТЕХНОЛОГИЧЕСКИЕ ПРЕДЕЛЫ ВЫЧИСЛЕНИЙ
На данном этапе технологического развития у нас нет ни достаточно мощного оборудования, ни необходимого ПО для создания сознательных умов в компьютерах. Но существуют убедительные аргументы, что если технологический прогресс продолжится, эти недостатки будут преодолены. Некоторые авторы утверждают, что эта стадия может наступить всего через несколько десятилетий [1]. Однако для наших целей не требуются предположения о временных масштабах. Аргумент симуляции работает одинаково хорошо и для тех, кто думает, что потребуются сотни тысяч лет, чтобы достичь «постчеловеческой» стадии.

Зрелая стадия технологического развития позволит превращать планеты и другие астрономические ресурсы в мощные компьютеры. Сейчас трудно уверенно назвать верхний предел вычислительной мощности постчеловеческих цивилизаций. Поскольку у нас нет «теории всего», мы не можем исключить использование новых физических феноменов для преодоления текущих ограничений [2].

Мы можем с гораздо большей уверенностью установить нижние границы, предполагая только уже понятные механизмы. Эрик Дрекслер описал проект системы размером с кубик сахара, выполняющей $10^{21}$ инструкций в секунду [3]. Другой автор дает грубую оценку $10^{42}$ операций в секунду для компьютера с массой большой планеты [4]. (Использование квантовых компьютеров или ядерной материи могло бы приблизить нас к теоретическим пределам — Сет Ллойд рассчитывает верхний предел для 1 кг компьютера как $5 \times 10^{50}$ логических операций в секунду [5]. Однако для наших целей достаточно консервативных оценок).

Мощность, необходимая для эмуляции человеческого разума, также может быть оценена. Оценка, основанная на копировании функциональности сетчатки, дает цифру $\sim10^{14}$ операций в секунду для всего человеческого мозга [6]. Альтернативная оценка, основанная на числе синапсов, дает $\sim10^{16}-10^{17}$ операций в секунду [7]. Возможно, потребуется больше, если нужно симулировать дендритные деревья, но высокая избыточность нервной системы позволяет ожидать выигрыша в эффективности при использовании небиологических процессоров.

Память кажется менее строгим ограничением [8]. Поскольку максимальная пропускная способность сенсорных каналов человека составляет $\sim10^8$ бит в секунду, симуляция всех сенсорных событий имеет ничтожную стоимость по сравнению с симуляцией активности коры.

Если в симуляцию включена окружающая среда, это потребует дополнительной мощности. Симуляция всей вселенной до квантового уровня очевидно невозможна. Но для реалистичной симуляции человеческого опыта требуется гораздо меньше — только то, что нужно, чтобы симулированные люди не замечали неправильностей. Микроскопическая структура Земли может быть опущена; удаленные астрономические объекты могут иметь сжатые представления. Макроскопические объекты на поверхности Земли нужно симулировать непрерывно, но микроскопические феномены можно заполнять *ad hoc*. Когда человек смотрит в микроскоп, симуляция может подставить нужную картинку.

Постчеловеческий симулятор будет иметь достаточно мощности, чтобы отслеживать состояния веры во всех человеческих мозгах. Поэтому, когда он увидит, что человек собирается наблюдать микромир, он заполнит детали в соответствующей области. Если возникнет ошибка, «режиссер» может отредактировать состояния мозгов или «отмотать» симуляцию назад.

Кажется правдоподобным, что основная вычислительная стоимость реалистичной симуляции заключается в симуляции органических мозгов [9]. Хотя точная оценка невозможна, мы можем использовать $\sim10^{33}-10^{36}$ операций как грубую оценку стоимости симуляции всей истории человечества [10]. Даже если наша оценка ошибается на несколько порядков, это не имеет большого значения. Один планетарный компьютер ($10^{42}$ оп/сек) может симулировать всю ментальную историю человечества (назовем это *симуляцией предков*), используя менее одной миллионной своей мощности за одну секунду. Постчеловеческая цивилизация может построить астрономическое число таких компьютеров.

Мы можем заключить, что вычислительная мощность, доступная постчеловеческой цивилизации, достаточна для запуска огромного количества симуляций предков, даже если она выделяет на это лишь ничтожную долю своих ресурсов.

## IV. ЯДРО АРГУМЕНТА СИМУЛЯЦИИ
Основная идея: если есть существенный шанс, что наша цивилизация достигнет постчеловеческой стадии и запустит много симуляций предков, то почему вы не живете в одной из них?

Введем следующие обозначения:
* **$f_P$**: Доля всех цивилизаций человеческого уровня, которые выживают и достигают постчеловеческой стадии.
* **$\bar{N}$**: Среднее число симуляций предков, запускаемых постчеловеческой цивилизацией.
* **$\bar{H}$**: Среднее число индивидуумов, живших в цивилизации до достижения постчеловеческой стадии.

Фактическая доля всех наблюдателей с человеческим опытом, живущих в симуляциях, составляет:
$$f_{sim} = \frac{f_P \bar{N} \bar{H}}{(f_P \bar{N} \bar{H}) + \bar{H}}$$

Обозначим $f_I$ как долю постчеловеческих цивилизаций, которые *заинтересованы* в запуске симуляций предков (и имеют ресурсы), и $\bar{N_I}$ как среднее число симуляций, запускаемых такими заинтересованными цивилизациями.
Тогда:
$$\bar{N} = f_I \bar{N_I}$$
И:
$$f_{sim} = \frac{f_P f_I \bar{N_I}}{(f_P f_I \bar{N_I}) + 1} \quad (*)$$

Из-за огромной вычислительной мощности постлюдей, $\bar{N_I}$ чрезвычайно велико. Глядя на уравнение $(*)$, мы видим, что по крайней мере одно из следующих трех утверждений должно быть истинным:
1.  $f_P \approx 0$
2.  $f_I \approx 0$
3.  $f_{sim} \approx 1$

## V. БЛЕДНЫЙ ПРИНЦИП БЕЗРАЗЛИЧИЯ
Мы можем сделать следующий шаг и заключить, что при условии истинности (3), наша вера (credence) в гипотезу о том, что мы в симуляции, должна быть близка к единице. В более общем виде, если мы знаем, что доля $x$ всех наблюдателей живет в симуляциях, и у нас нет специфической информации, отличающей нас, то наша вера в то, что мы в симуляции, должна равняться $x$:
$$Cr(SIM | f_{sim} = x) = x \quad (\#)$$

Этот шаг санкционирован очень слабым «принципом безразличия». Даже если умы качественно отличаются, аргумент работает, если у нас нет информации, позволяющей предсказать, кто симулирован, а кто нет. Детальная защита этого принципа дана в литературе [11].

Рассмотрим аналогию: предположим, что $x\%$ населения имеет определенную генетическую последовательность $S$ в «мусорной ДНК», которая никак не проявляется. Если вы не секвенировали свою ДНК, рационально присвоить вероятность $x\%$ тому, что у вас есть $S$. То же самое справедливо, если $S$ — это свойство «быть в симуляции».

Принцип, выраженный в $(\#)$, предписывает безразличие только между гипотезами о том, *каким наблюдателем вы являетесь*, когда у вас нет информации об этом. Он не подвержен парадоксу Бертрана. Читатели, знакомые с *Doomsday argument* [12], могут беспокоиться, но «бледный принцип безразличия» намного слабее и применяется только к случаям, где у нас нет информации о принадлежности к группе.

Также стоит заметить: если бы все делали ставку на то, в симуляции они или нет, и использовали этот принцип, то в случае, когда почти все люди находятся в симуляции, почти все выиграли бы свои ставки.

## VI. ИНТЕРПРЕТАЦИЯ
Возможность, представленная утверждением **(1)**, довольно прямолинейна. Если (1) истинно, то человечество почти наверняка не достигнет постчеловеческого уровня. Следовательно, условная вероятность DOOM (гибели) высока. Самая естественная интерпретация (1) — мы, вероятно, вымрем в результате развития какой-то мощной, но опасной технологии [13], например, молекулярных нанотехнологий [14].

Вторая альтернатива **(2)** заключается в том, что доля постчеловеческих цивилизаций, заинтересованных в симуляциях, ничтожно мала. Для этого требуется сильная конвергенция курсов развития цивилизаций. Возможно, все развитые цивилизации принимают этический запрет на симуляции из-за страданий их обитателей. Однако с нашей нынешней точки зрения создание человеческой расы не кажется аморальным. Либо постлюди теряют желание запускать симуляции, считая их неэффективным способом получения удовольствия по сравнению с прямой стимуляцией центров вознаграждения. Вывод из (2): постчеловеческие общества будут сильно отличаться от человеческих.

Возможность, выраженная альтернативой **(3)**, концептуально наиболее интригующая. Если мы живем в симуляции, то наблюдаемый нами космос — лишь крошечная часть реальности. Физика в мире симулятора может отличаться от нашей. Симулированные цивилизации могут стать постчеловеческими и запустить свои собственные симуляции («виртуальные машины»). Реальность может содержать много уровней.

Если мы сами запустим симуляции предков, это будет сильным свидетельством против (1) и (2), и нам придется заключить, что мы живем в симуляции. Более того, мы должны будем подозревать, что наши создатели сами являются симулированными существами.

Постлюди, запускающие симуляцию, подобны богам по отношению к людям в симуляции: они создали мир, они сверхразумны, «всемогущи» и «всеведущи» в рамках этого мира. Возможно существование «загробной жизни» или наказаний/наград от симуляторов.

В дополнение к симуляциям предков возможны выборочные симуляции (малые группы или одиночные индивиды). Остальные люди тогда были бы «зомби» или «людьми-тенями». Но чтобы большинство симулированных людей находилось в одиночных симуляциях («me-simulations»), их должно быть в 100 миллиардов раз больше, чем полных симуляций.

Предполагая, что мы живем в симуляции, последствия не так радикальны. Нашим лучшим гидом остается эмпирическое изучение наблюдаемой вселенной. Истинность (3) не должна заставлять нас «сходить с ума» или мешать строить планы [15].

## VII. ЗАКЛЮЧЕНИЕ
Технологически зрелая цивилизация обладала бы огромной вычислительной мощностью. Основываясь на этом эмпирическом факте, аргумент симуляции показывает, что истинно как минимум одно из следующих утверждений:
1.  Доля цивилизаций человеческого уровня, которые достигают постчеловеческой стадии, очень близка к нулю.
2.  Доля постчеловеческих цивилизаций, которые заинтересованы в запуске симуляций предков, очень близка к нулю.
3.  Доля всех людей с нашим типом опыта, которые живут в симуляции, очень близка к единице.

Если (1) истинно, мы почти наверняка вымрем до достижения постчеловечности.
Если (2) истинно, существует сильная конвергенция, исключающая желание запускать симуляции.
Если (3) истинно, мы почти наверняка живем в симуляции.

В «темном лесу» нашего нынешнего неведения кажется разумным распределить свою веру (credence) примерно поровну между (1), (2) и (3).
Если только мы сейчас не живем в симуляции, наши потомки почти наверняка никогда не запустят симуляцию предков.

---

### Благодарности
Я благодарен многим людям за комментарии, и особенно Amara Angelica, Robert Bradbury, Milan Cirkovic, Robin Hanson, Hal Finney, Robert A. Freitas Jr., John Leslie, Mitch Porter, Keith DeRose, Mike Treder, Mark Walker, Eliezer Yudkowsky и анонимным рецензентам.

### Список литературы

1.  См. напр. **K. E. Drexler**, *Engines of Creation: The Coming Era of Nanotechnology*, London, Forth Estate, 1985;
    **N. Bostrom**, "How Long Before Superintelligence?", *International Journal of Futures Studies*, vol. 2, (1998);
    **R. Kurzweil**, *The Age of Spiritual Machines: When computers exceed human intelligence*, New York, Viking Press, 1999;
    **H. Moravec**, *Robot: Mere Machine to Transcendent Mind*, Oxford University Press, 1999.

2.  Такие как предел Бремермана-Бекенштейна и предел черной дыры (см. **H. J. Bremermann** (1982), **J. D. Bekenstein** (1984), **A. Sandberg** (1999)).

3.  **K. E. Drexler**, *Nanosystems: Molecular Machinery, Manufacturing, and Computation*, New York, John Wiley & Sons, Inc., 1992.

4.  **R. J. Bradbury**, "Matrioshka Brains", Working manuscript (2002), [http://www.aeiveos.com/~bradbury/MatrioshkaBrains/MatrioshkaBrains.html](http://www.aeiveos.com/~bradbury/MatrioshkaBrains/MatrioshkaBrains.html).

5.  **S. Lloyd**, "Ultimate physical limits to computation", *Nature* 406 (31 August): 1047-1054 (2000).

6.  **H. Moravec**, *Mind Children*, Harvard University Press (1989).

7.  **Bostrom** (1998), op. cit.

8.  См. ссылки в предыдущих сносках.

9.  По мере создания более быстрых компьютеров, стоимость симуляции самих машин может превысить стоимость симуляции нервных систем.

10. $100 \text{ млрд людей} \times 50 \text{ лет} \times 30 \text{ млн сек} \times [10^{14}, 10^{17}] \text{ оп/сек} \approx [10^{33}, 10^{36}] \text{ операций}$.

11. См. напр. **N. Bostrom**, "The Doomsday argument...", *Synthese* 127(3) (2001); и книгу *Anthropic Bias*, Routledge, 2002.

12. См. напр. **J. Leslie**, "Is the End of the World Nigh?", *Philosophical Quarterly* 40 (1990).

13. См. мою статью "Existential Risks...", *Journal of Evolution and Technology*, vol. 9 (2001).

14. См. напр. **Drexler** (1985) и **R. A. Freitas Jr.**, "Some Limits to Global Ecophagy...", Zyvex preprint (2000).

15. См. **R. Hanson**, "How to Live in a Simulation", *Journal of Evolution and Technology*, vol. 7 (2001).
